{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d9084dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss: 1.1048, Acc: 0.4242 | Val Loss: 1.4710, Acc: 0.7000 | Time: 11.0s\n",
      "✅ Saved new best model\n",
      "Epoch 02 | Train Loss: 0.2705, Acc: 0.9091 | Val Loss: 2.1072, Acc: 0.7000 | Time: 17.0s\n",
      "Epoch 03 | Train Loss: 0.0919, Acc: 0.9697 | Val Loss: 2.5074, Acc: 0.7000 | Time: 14.8s\n",
      "Epoch 04 | Train Loss: 0.0672, Acc: 0.9697 | Val Loss: 2.8135, Acc: 0.6000 | Time: 13.6s\n",
      "Epoch 05 | Train Loss: 0.0848, Acc: 0.9394 | Val Loss: 2.6938, Acc: 0.7000 | Time: 12.7s\n",
      "Epoch 06 | Train Loss: 0.0594, Acc: 0.9697 | Val Loss: 2.2710, Acc: 0.7000 | Time: 12.3s\n",
      "Epoch 07 | Train Loss: 0.0478, Acc: 0.9697 | Val Loss: 1.9186, Acc: 0.7000 | Time: 12.5s\n",
      "Epoch 08 | Train Loss: 0.0570, Acc: 0.9697 | Val Loss: 1.5269, Acc: 0.7000 | Time: 12.7s\n",
      "Epoch 09 | Train Loss: 0.0500, Acc: 1.0000 | Val Loss: 1.2805, Acc: 0.9000 | Time: 12.6s\n",
      "✅ Saved new best model\n",
      "Epoch 10 | Train Loss: 0.0490, Acc: 0.9697 | Val Loss: 1.1996, Acc: 0.8000 | Time: 12.8s\n",
      "Epoch 11 | Train Loss: 0.0495, Acc: 0.9697 | Val Loss: 1.2679, Acc: 0.9000 | Time: 12.5s\n",
      "Epoch 12 | Train Loss: 0.0454, Acc: 0.9697 | Val Loss: 1.3891, Acc: 0.7000 | Time: 12.5s\n",
      "Epoch 13 | Train Loss: 0.0413, Acc: 1.0000 | Val Loss: 1.3086, Acc: 0.7000 | Time: 13.1s\n",
      "Epoch 14 | Train Loss: 0.0436, Acc: 1.0000 | Val Loss: 1.4335, Acc: 0.8000 | Time: 13.0s\n",
      "Epoch 15 | Train Loss: 0.0409, Acc: 1.0000 | Val Loss: 1.3815, Acc: 0.8000 | Time: 14.1s\n",
      "Training done! Best Val Acc: 0.9\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import time\n",
    "\n",
    "# 1. Tiền xử lý + Augmentation (giúp tránh overfitting)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 2. Dataset + DataLoader\n",
    "train_dataset = datasets.ImageFolder(\"dataset/train\", transform=train_transform)\n",
    "val_dataset   = datasets.ImageFolder(\"dataset/val\",   transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "# 3. Load pretrained ResNet18 (fine-tune toàn bộ model)\n",
    "model = models.resnet18(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 3)  # 3 class\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# 4. Loss, optimizer, scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# 5. Train + Validation loop\n",
    "best_acc = 0.0\n",
    "for epoch in range(15):  \n",
    "    start_time = time.time()\n",
    "\n",
    "    # --- Train ---\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_loss = running_loss / len(train_dataset)\n",
    "    train_acc = correct / total\n",
    "\n",
    "    # --- Validation ---\n",
    "    model.eval()\n",
    "    val_loss, correct, total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    val_loss /= len(val_dataset)\n",
    "    val_acc = correct / total\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Epoch {epoch+1:02d} | \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f} | \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f} | \"\n",
    "          f\"Time: {elapsed:.1f}s\")\n",
    "\n",
    "    # Lưu model tốt nhất\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_resnet18.pth\")\n",
    "        print(\"✅ Saved new best model\")\n",
    "\n",
    "print(\"Training done! Best Val Acc:\", best_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34858620",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Load lại model\n",
    "model = models.resnet18(pretrained=False)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 3)  # 3 classes: nothing, pallet_empty, pallet_loaded\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.load_state_dict(torch.load(\"best_resnet18.pth\", map_location=device))\n",
    "model = model.to(device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7c87bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80c34ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Danh sách class phải giống với thư mục bạn train\n",
    "class_names = [\"nothing\", \"pallet_empty\", \"pallet_loaded\"]\n",
    "\n",
    "def predict_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    img = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(img)\n",
    "        _, predicted = outputs.max(1)\n",
    "\n",
    "    return class_names[predicted.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73a56760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nothing\n",
      "pallet_empty\n"
     ]
    }
   ],
   "source": [
    "print(predict_image(r\"D:\\Lab\\AGV\\AI\\Vision\\Pallet\\dataset\\test\\empty_pallet\\0019.jpg\"))\n",
    "print(predict_image(r\"D:\\Lab\\AGV\\AI\\Vision\\Pallet\\dataset\\test\\loaded_pallet\\0020.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f56d861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class order used by the model: ['empty_pallet', 'loaded_pallet', 'nothing']\n",
      "('loaded_pallet', {'empty_pallet': 5.1589373470051214e-05, 'loaded_pallet': 0.9790634512901306, 'nothing': 0.02088490128517151})\n",
      "('loaded_pallet', {'empty_pallet': 0.059533264487981796, 'loaded_pallet': 0.7327089905738831, 'nothing': 0.20775775611400604})\n",
      "('loaded_pallet', {'empty_pallet': 5.444834641821217e-06, 'loaded_pallet': 0.9966446161270142, 'nothing': 0.0033499787095934153})\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms, datasets\n",
    "from PIL import Image\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 1) Lấy đúng thứ tự class từ train\n",
    "train_dir = r\"D:\\Lab\\AGV\\AI\\Vision\\Pallet\\dataset\\train\"  # đổi đúng đường dẫn của bạn\n",
    "class_names = datasets.ImageFolder(train_dir).classes\n",
    "print(\"Class order used by the model:\", class_names)  # kiểm tra\n",
    "\n",
    "# 2) Khởi tạo model đúng số lớp và load trọng số\n",
    "model = models.resnet18(pretrained=False)\n",
    "model.fc = nn.Linear(model.fc.in_features, len(class_names))\n",
    "model.load_state_dict(torch.load(\"best_resnet18.pth\", map_location=device))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# 3) Tiền xử lý phải GIỐNG lúc train\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def predict_image(path):\n",
    "    img = Image.open(path).convert(\"RGB\")\n",
    "    x = transform(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(x)\n",
    "        probs = torch.softmax(logits, dim=1)[0]\n",
    "        pred = probs.argmax().item()\n",
    "    return class_names[pred], {cls: float(probs[i]) for i, cls in enumerate(class_names)}\n",
    "\n",
    "# Test lại\n",
    "print(predict_image(r\"D:\\Lab\\AGV\\AI\\Vision\\Pallet\\dataset\\test\\loaded_pallet\\0021.jpg\"))\n",
    "print(predict_image(r\"D:\\Lab\\AGV\\AI\\Vision\\Pallet\\dataset\\test\\loaded_pallet\\0020.jpg\"))\n",
    "print(predict_image(r\"D:\\Lab\\AGV\\AI\\Vision\\Pallet\\dataset\\test\\nothing\\0007.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f4548c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.8\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      " [[2 0 0]\n",
      " [0 2 0]\n",
      " [0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "test_dir = r\"D:\\Lab\\AGV\\AI\\Vision\\Pallet\\dataset\\test\"\n",
    "test_ds = datasets.ImageFolder(test_dir, transform=transform)\n",
    "test_loader = DataLoader(test_ds, batch_size=32, shuffle=False)\n",
    "\n",
    "correct, total = 0, 0\n",
    "conf = torch.zeros(len(class_names), len(class_names), dtype=torch.int64)\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        pred = model(x).argmax(1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        total += y.size(0)\n",
    "        for t, p in zip(y.view(-1), pred.view(-1)):\n",
    "            conf[t, p] += 1\n",
    "\n",
    "print(\"Test Acc:\", correct/total)\n",
    "print(\"Confusion matrix (rows=true, cols=pred):\\n\", conf.cpu().numpy())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
