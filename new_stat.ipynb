{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3164809e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> ƒêang s·ª≠ d·ª•ng: cuda:0\n",
      ">>> GPU: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "Classes: ['nothing', 'pallet']\n",
      "Epoch 01 | Train Acc: 0.5000 | Val Acc: 0.3636 | Time: 9.6s\n",
      "‚úÖ Saved new best model\n",
      "Epoch 02 | Train Acc: 0.8485 | Val Acc: 0.4545 | Time: 10.1s\n",
      "‚úÖ Saved new best model\n",
      "Epoch 03 | Train Acc: 0.9697 | Val Acc: 0.5455 | Time: 9.8s\n",
      "‚úÖ Saved new best model\n",
      "Epoch 04 | Train Acc: 0.9545 | Val Acc: 0.5455 | Time: 9.4s\n",
      "Epoch 05 | Train Acc: 0.9697 | Val Acc: 0.4545 | Time: 9.7s\n",
      "Epoch 06 | Train Acc: 0.9848 | Val Acc: 0.5455 | Time: 10.9s\n",
      "Epoch 07 | Train Acc: 1.0000 | Val Acc: 0.6364 | Time: 9.8s\n",
      "‚úÖ Saved new best model\n",
      "Epoch 08 | Train Acc: 0.9697 | Val Acc: 0.6364 | Time: 9.6s\n",
      "Epoch 09 | Train Acc: 1.0000 | Val Acc: 0.6364 | Time: 9.7s\n",
      "Epoch 10 | Train Acc: 0.9848 | Val Acc: 0.6364 | Time: 9.5s\n",
      "Epoch 11 | Train Acc: 1.0000 | Val Acc: 0.8182 | Time: 9.8s\n",
      "‚úÖ Saved new best model\n",
      "Epoch 12 | Train Acc: 0.9848 | Val Acc: 0.7273 | Time: 9.7s\n",
      "Epoch 13 | Train Acc: 0.9848 | Val Acc: 0.7273 | Time: 9.9s\n",
      "Epoch 14 | Train Acc: 0.9394 | Val Acc: 0.7273 | Time: 10.2s\n",
      "Epoch 15 | Train Acc: 0.9848 | Val Acc: 0.6364 | Time: 10.0s\n",
      "Epoch 16 | Train Acc: 0.9848 | Val Acc: 0.7273 | Time: 10.1s\n",
      "‚èπ Early stopping\n",
      "Best Val Acc (Detector): 0.8181818181818182\n"
     ]
    }
   ],
   "source": [
    "# ================== 1. Import ==================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import time, os\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\">>> ƒêang s·ª≠ d·ª•ng:\", device)\n",
    "if device.type == \"cuda\":\n",
    "    print(\">>> GPU:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# ================== 2. Data ==================\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.7, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# üëâ dataset b√¢y gi·ªù ch·ªâ c√≥ 2 class: \"pallet\" v√† \"nothing\"\n",
    "train_dir = \"dataset_step1/images/train\"\n",
    "val_dir   = \"dataset_step1/images/val\"\n",
    "\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=train_transform)\n",
    "val_dataset   = datasets.ImageFolder(val_dir,   transform=test_transform)\n",
    "class_names = train_dataset.classes\n",
    "print(\"Classes:\", class_names)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "# ================== 3. Model ==================\n",
    "modelA = models.efficientnet_b0(pretrained=True)\n",
    "num_ftrs = modelA.classifier[1].in_features\n",
    "modelA.classifier[1] = nn.Linear(num_ftrs, len(class_names))\n",
    "modelA = modelA.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(modelA.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=10)\n",
    "\n",
    "# ================== 4. Training ==================\n",
    "best_acc, patience, trigger = 0.0, 5, 0\n",
    "for epoch in range(30):\n",
    "    start = time.time()\n",
    "    # Train\n",
    "    modelA.train()\n",
    "    train_loss, train_correct, train_total = 0, 0, 0\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = modelA(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * x.size(0)\n",
    "        train_correct += (out.argmax(1) == y).sum().item()\n",
    "        train_total += y.size(0)\n",
    "    train_acc = train_correct / train_total\n",
    "\n",
    "    # Val\n",
    "    modelA.eval()\n",
    "    val_loss, val_correct, val_total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = modelA(x)\n",
    "            loss = criterion(out, y)\n",
    "            val_loss += loss.item() * x.size(0)\n",
    "            val_correct += (out.argmax(1) == y).sum().item()\n",
    "            val_total += y.size(0)\n",
    "    val_acc = val_correct / val_total\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1:02d} | Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f} | Time: {time.time()-start:.1f}s\")\n",
    "\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(modelA.state_dict(), \"pallet_detector.pth\")\n",
    "        print(\"‚úÖ Saved new best model\")\n",
    "        trigger = 0\n",
    "    else:\n",
    "        trigger += 1\n",
    "        if trigger >= patience:\n",
    "            print(\"‚èπ Early stopping\")\n",
    "            break\n",
    "\n",
    "print(\"Best Val Acc (Detector):\", best_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7226e11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> ƒêang s·ª≠ d·ª•ng: cuda:0\n",
      ">>> GPU: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "Classes: ['empty_pallet', 'loaded_pallet']\n",
      "Epoch 01 | Train Acc: 0.5294 | Val Acc: 0.7500 | Time: 10.5s\n",
      "‚úÖ Saved new best model\n",
      "Epoch 02 | Train Acc: 0.6275 | Val Acc: 0.7750 | Time: 10.6s\n",
      "‚úÖ Saved new best model\n",
      "Epoch 03 | Train Acc: 0.8235 | Val Acc: 0.7750 | Time: 10.8s\n",
      "Epoch 04 | Train Acc: 0.8431 | Val Acc: 0.7750 | Time: 10.4s\n",
      "Epoch 05 | Train Acc: 0.9020 | Val Acc: 0.7750 | Time: 12.2s\n",
      "Epoch 06 | Train Acc: 0.9804 | Val Acc: 0.7250 | Time: 13.9s\n",
      "Epoch 07 | Train Acc: 0.9608 | Val Acc: 0.7500 | Time: 10.8s\n",
      "‚èπ Early stopping\n",
      "Best Val Acc (Classifier): 0.775\n"
     ]
    }
   ],
   "source": [
    "# ================== 1. Import ==================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import time, os\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\">>> ƒêang s·ª≠ d·ª•ng:\", device)\n",
    "if device.type == \"cuda\":\n",
    "    print(\">>> GPU:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# ================== 2. Data ==================\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.7, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# üëâ dataset b√¢y gi·ªù ch·ªâ c√≥ 2 class: \"empty_pallet\", \"loaded_pallet\"\n",
    "train_dir = \"dataset_step2/images/train\"\n",
    "val_dir   = \"dataset_step2/images/val\"\n",
    "\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=train_transform)\n",
    "val_dataset   = datasets.ImageFolder(val_dir,   transform=test_transform)\n",
    "class_names = train_dataset.classes\n",
    "print(\"Classes:\", class_names)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "# ================== 3. Model ==================\n",
    "modelB = models.efficientnet_b0(pretrained=True)\n",
    "num_ftrs = modelB.classifier[1].in_features\n",
    "modelB.classifier[1] = nn.Linear(num_ftrs, len(class_names))\n",
    "modelB = modelB.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(modelB.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=10)\n",
    "\n",
    "# ================== 4. Training ==================\n",
    "best_acc, patience, trigger = 0.0, 5, 0\n",
    "for epoch in range(30):\n",
    "    start = time.time()\n",
    "    # Train\n",
    "    modelB.train()\n",
    "    train_loss, train_correct, train_total = 0, 0, 0\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = modelB(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * x.size(0)\n",
    "        train_correct += (out.argmax(1) == y).sum().item()\n",
    "        train_total += y.size(0)\n",
    "    train_acc = train_correct / train_total\n",
    "\n",
    "    # Val\n",
    "    modelB.eval()\n",
    "    val_loss, val_correct, val_total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = modelB(x)\n",
    "            loss = criterion(out, y)\n",
    "            val_loss += loss.item() * x.size(0)\n",
    "            val_correct += (out.argmax(1) == y).sum().item()\n",
    "            val_total += y.size(0)\n",
    "    val_acc = val_correct / val_total\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1:02d} | Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f} | Time: {time.time()-start:.1f}s\")\n",
    "\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(modelB.state_dict(), \"pallet_classifier.pth\")\n",
    "        print(\"‚úÖ Saved new best model\")\n",
    "        trigger = 0\n",
    "    else:\n",
    "        trigger += 1\n",
    "        if trigger >= patience:\n",
    "            print(\"‚èπ Early stopping\")\n",
    "            break\n",
    "\n",
    "print(\"Best Val Acc (Classifier):\", best_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ab27483",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:57: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<>:57: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<>:57: SyntaxWarning: invalid escape sequence '\\L'\n",
      "<string>:57: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<>:57: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<>:57: SyntaxWarning: invalid escape sequence '\\L'\n",
      "C:\\Users\\ducho\\AppData\\Local\\Temp\\ipykernel_15884\\2707743042.py:57: SyntaxWarning: invalid escape sequence '\\{'\n",
      "  result = infer_pipeline(f\"D:\\LAB\\{i}.jpg\")\n",
      "C:\\Users\\ducho\\AppData\\Local\\Temp\\ipykernel_15884\\2707743042.py:57: SyntaxWarning: invalid escape sequence '\\L'\n",
      "  result = infer_pipeline(f\"D:\\LAB\\{i}.jpg\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: {'label': 'Loaded Pallet', 'confidence': 0.5987045168876648}\n",
      "Result: {'label': 'Loaded Pallet', 'confidence': 0.6071726679801941}\n",
      "Result: {'label': 'Loaded Pallet', 'confidence': 0.651948094367981}\n",
      "Result: {'label': 'Loaded Pallet', 'confidence': 0.7191992998123169}\n",
      "Result: {'label': 'Loaded Pallet', 'confidence': 0.6772565245628357}\n",
      "Result: {'label': 'Loaded Pallet', 'confidence': 0.6772565245628357}\n",
      "Result: {'label': 'Loaded Pallet', 'confidence': 0.7914567589759827}\n",
      "Result: {'label': 'No Pallet', 'confidence': 0.5124083161354065}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "\n",
    "# ---- Step 1: Load models ----\n",
    "def load_model_efficientnet(num_classes, weight_path):\n",
    "    model = models.efficientnet_b0(pretrained=False)\n",
    "    num_ftrs = model.classifier[1].in_features\n",
    "    model.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "    state_dict = torch.load(weight_path, map_location=\"cpu\")\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# model1: C√≥ pallet hay kh√¥ng\n",
    "model1 = load_model_efficientnet(2, \"pallet_detector.pth\")\n",
    "\n",
    "# model2: Empty pallet vs Loaded pallet\n",
    "model2 = load_model_efficientnet(2, \"pallet_classifier.pth\")\n",
    "\n",
    "# ---- Step 2: Preprocessing ----\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# ---- Step 3: Inference Pipeline ----\n",
    "def infer_pipeline(image_path):\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    x = transform(img).unsqueeze(0)  # (1, C, H, W)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Step 1: Pallet vs Nothing\n",
    "        out1 = model1(x)\n",
    "        prob1 = torch.softmax(out1, dim=1)\n",
    "        pred1 = torch.argmax(prob1, dim=1).item()\n",
    "\n",
    "    if pred1 == 0:  \n",
    "        return {\"label\": \"No Pallet\", \"confidence\": prob1[0][0].item()}\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            # Step 2: Empty vs Loaded\n",
    "            out2 = model2(x)\n",
    "            prob2 = torch.softmax(out2, dim=1)\n",
    "            pred2 = torch.argmax(prob2, dim=1).item()\n",
    "\n",
    "        if pred2 == 0:\n",
    "            return {\"label\": \"Empty Pallet\", \"confidence\": prob2[0][0].item()}\n",
    "        else:\n",
    "            return {\"label\": \"Loaded Pallet\", \"confidence\": prob2[0][1].item()}\n",
    "\n",
    "# ---- Test th·ª≠ ----\n",
    "for i in range (1, 9):\n",
    "    result = infer_pipeline(f\"D:\\LAB\\{i}.jpg\")\n",
    "    print(\"Result:\", result)\n",
    "# result = infer_pipeline(r\"D:\\LAB\\nothing.jpg\")\n",
    "# print(\"Result:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf10752",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
